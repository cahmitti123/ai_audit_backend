# =============================================================================
# AI Audit System - Environment variables
#
# This is the single canonical env template.
# - Local dev: copy to `.env`
# - Docker/VPS: copy to `.env` or `.env.production` (compose uses `--env-file`)
#
# Detailed docs: `docs/env.md`
# =============================================================================

# Database
DATABASE_URL="postgresql://user:password@localhost:5432/ai_audit"
DIRECT_URL="postgresql://user:password@localhost:5432/ai_audit"

# Fiche API
FICHE_API_BASE_URL="https://your-api-url.com"
# Optional: only if your CRM/API requires auth (not used by all deployments)
# FICHE_API_AUTH_TOKEN="your-token"

# Optional API authentication for THIS backend (disabled unless set)
# Provide via `Authorization: Bearer <token>` or `X-API-Key: <token>`
# API_AUTH_TOKEN="your-backend-api-token"
# API_AUTH_TOKENS="token1,token2"

# User authentication (JWT + refresh tokens)
# =========================================
# Access tokens are JWTs (Authorization: Bearer <jwt>), refresh tokens are DB-backed and rotated.
#
# Required to enable JWT auth:
# JWT_ACCESS_SECRET="change-me" # generate: openssl rand -hex 32
#
# Optional (recommended):
# JWT_ISSUER="ai-audit"
# JWT_AUDIENCE="ai-audit"
# AUTH_ACCESS_TTL_SECONDS="900"       # 15 minutes
# AUTH_REFRESH_TTL_SECONDS="2592000"  # 30 days
#
# Refresh cookie settings (for browser clients)
# - For cross-site (frontend on a different domain): set SameSite=none + Secure=1
# AUTH_REFRESH_COOKIE_NAME="refresh_token"
# AUTH_COOKIE_SECURE="0"
# AUTH_COOKIE_SAMESITE="lax" # lax|strict|none
#
# Seed an initial admin user when running `npm run seed`
# AUTH_SEED_ADMIN_EMAIL="admin@example.com"
# AUTH_SEED_ADMIN_PASSWORD="change-me"

# AI Services
OPENAI_API_KEY="your-openai-key"
ANTHROPIC_API_KEY="your-anthropic-key"

# OpenAI models (defaults are safe; override per environment as needed)
# Docs: `https://platform.openai.com/docs/models/gpt-5.2`
OPENAI_MODEL_AUDIT="gpt-5.2"
OPENAI_MODEL_CHAT="gpt-5.2"
# Optional chat tuning (lower = less hallucination)
OPENAI_TEMPERATURE_CHAT="0"
# OPENAI_MAX_TOKENS_CHAT="3000"

# Audit accuracy / anti-hallucination
# If enabled, the backend will drop hallucinated citations (quotes not present in transcript chunks)
# and conservatively downgrade unsupported "PRESENT" claims.
AUDIT_EVIDENCE_GATING="1"
# Minimum normalized quote length (characters) for a citation to be considered valid.
# Lower values accept weaker evidence; higher values are stricter.
# AUDIT_EVIDENCE_MIN_QUOTE_CHARS="12"
# For product verification: vector-store fallback is opt-in (DB matching is preferred for accuracy)
PRODUCT_VECTORSTORE_FALLBACK="0"
# For product verification steps: use a smaller timeline excerpt to keep prompts focused & avoid context overflow
AUDIT_STEP_TIMELINE_EXCERPT="1"
AUDIT_STEP_TIMELINE_MAX_CHUNKS="40"

# Vector Store (Product Verification)
VECTOR_STORE_ID="vs_..."
VECTOR_STORE_MAX_RESULTS="5"

# ElevenLabs (Transcription)
ELEVENLABS_API_KEY="your-elevenlabs-key"
# Provider throttling / retry (optional)
# These protect you from ElevenLabs 429 errors when transcription fan-out is high (multi-replica).
# TRANSCRIPTION_ELEVENLABS_RATE_LIMIT_PER_MINUTE="10"
# TRANSCRIPTION_ELEVENLABS_MAX_ATTEMPTS="6"
# TRANSCRIPTION_ELEVENLABS_BACKOFF_BASE_SECONDS="2"
# TRANSCRIPTION_ELEVENLABS_BACKOFF_MAX_SECONDS="60"

# Inngest Configuration
# =====================
# Three modes available:
# 1. Development Mode (INNGEST_DEV=1): No external server needed, runs locally
# 2. Self-Hosted (INNGEST_DEV=0 + INNGEST_BASE_URL): Connects to Docker container
# 3. Cloud (INNGEST_DEV=0, no BASE_URL): Connects to Inngest Cloud (requires event key)

# Development mode (recommended for local dev)
INNGEST_DEV="1"

# For production/Docker (set INNGEST_DEV=0 and configure these):
# INNGEST_EVENT_KEY="your-inngest-event-key"
# INNGEST_SIGNING_KEY="0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
# INNGEST_BASE_URL="http://inngest:8288"

# Generate signing key with: openssl rand -hex 32

# Self-hosted Inngest polling (used by the Inngest server container, not the Node app):
# When set, Inngest will periodically re-poll the SDK URL so new function IDs/events are discovered
# without requiring a restart.
# INNGEST_POLL_INTERVAL="60"

# Webhook URL allowlist (Optional)
# ===============================
# SSRF protection for user-provided webhookUrl (progressive fetch):
# Comma-separated list of allowed URL origins (protocol + host + optional port).
# Example: WEBHOOK_ALLOWED_ORIGINS="http://localhost:3000,https://your-frontend.vercel.app"
WEBHOOK_ALLOWED_ORIGINS="http://localhost:3000"

# Pusher Channels (backend server SDK)
# ====================================
# Only PUSHER_KEY + PUSHER_CLUSTER go to the browser.
# Never expose PUSHER_SECRET or PUSHER_APP_ID to the client.
PUSHER_APP_ID=""
PUSHER_KEY=""
PUSHER_SECRET=""
PUSHER_CLUSTER=""
# Optional: allow backend to read the same key the Next.js app uses
# NEXT_PUBLIC_PUSHER_KEY=""
#
# Optional toggles:
# PUSHER_USE_PRIVATE_CHANNELS="1"
# PUSHER_MAX_PAYLOAD_BYTES="9000"
# PUSHER_DRY_RUN="0"

# Redis (shared coordination)
# Use Redis in production & multi-replica deployments.
# Local dev: `redis://localhost:6379`
REDIS_URL="redis://localhost:6379"

# Inngest concurrency scaling (recommended)
# ========================================
# Default global concurrency for most workers is computed as:
#   INNGEST_PARALLELISM_PER_SERVER * INNGEST_SERVER_REPLICAS
#
# - INNGEST_PARALLELISM_PER_SERVER: parallel work per server instance (default 10)
# - INNGEST_SERVER_REPLICAS: how many API server replicas you run (docker: `--scale server=N`)
#
# INNGEST_PARALLELISM_PER_SERVER="10"
# INNGEST_SERVER_REPLICAS="1"
#
# Optional: override specific workflow concurrency (advanced)
# ==========================================================
# - Global caps (across ALL replicas):
# AUDIT_RUN_CONCURRENCY="60"
# TRANSCRIPTION_FICHE_CONCURRENCY="60"
# FICHE_FETCH_CONCURRENCY="60"
# AUDIT_STEP_WORKER_CONCURRENCY="60"
# TRANSCRIPTION_RECORDING_WORKER_CONCURRENCY="60"
# TRANSCRIPTION_FINALIZER_CONCURRENCY="60"
# BATCH_AUDIT_PROGRESS_CONCURRENCY="60"
# PROGRESSIVE_FETCH_DAY_CONCURRENCY="60"
#
# - Per-entity caps:
# AUDIT_RUN_PER_FICHE_CONCURRENCY="1"
# AUDIT_STEP_PER_AUDIT_CONCURRENCY="10"
# TRANSCRIPTION_RECORDING_PER_FICHE_CONCURRENCY="10"
#
# - In-process parallelism (per server instance):
# AUDIT_STEP_CONCURRENCY="10"
# TRANSCRIPTION_RECORDING_CONCURRENCY="10"
# FICHE_SALES_CACHE_CONCURRENCY="10"
# TRANSCRIPTION_PROGRESS_WEBHOOK_FREQUENCY="3"
# TRANSCRIPTION_RUN_STATE_TTL_SECONDS="7200"
# TRANSCRIPTION_LOCK_TTL_MS="1800000"
# AUDIT_BATCH_STATE_TTL_SECONDS="21600"
# AUTOMATION_SCHEDULER_WINDOW_MINUTES="20"
# AUTOMATION_SCHEDULER_CRON="*/1 * * * *"
#
# Automation run polling (optional tuning)
# AUTOMATION_FICHE_DETAILS_MAX_WAIT_MS="600000"
# AUTOMATION_FICHE_DETAILS_POLL_INTERVAL_SECONDS="20"
# AUTOMATION_TRANSCRIPTION_MAX_WAIT_MS="900000"
# AUTOMATION_TRANSCRIPTION_POLL_INTERVAL_SECONDS="30"
# AUTOMATION_AUDIT_MAX_WAIT_MS="1800000"
# AUTOMATION_AUDIT_POLL_INTERVAL_SECONDS="60"
#
# Workflow tracer logging (optional, cross-workflow observability)
# ==============================================================
# Some workflows can emit structured logs to:
# - stdout (normal app logs)
# - local files (append-only)
# - DB table `workflow_logs` (queried by /api/*/logs endpoints)
#
# Enable DB persistence for workflow logs (default: disabled)
# WORKFLOW_LOG_DB_ENABLED="1"
#
# Enable file persistence (default: disabled). Files are written to:
#   ./workflow-debug-logs/*.txt
# You can enable it globally or per-workflow:
# WORKFLOW_DEBUG_LOG_TO_FILE="1"
# AUDIT_DEBUG_LOG_TO_FILE="1"
# TRANSCRIPTION_DEBUG_LOG_TO_FILE="1"
# FICHE_DEBUG_LOG_TO_FILE="1"
#
# Automation debug logging (optional)
# If enabled, the `automation/run` orchestrator also writes a txt log file to:
#   ./automation-debug-logs/automation-run-<RUN_ID>.txt
# NOTE: In multi-replica deployments, fan-out workers may run on other containers,
# so this file primarily captures orchestrator-level debug logs.
# AUTOMATION_DEBUG_LOG_TO_FILE="0"
#
# Automation safety: ignore fiches with too many recordings (protects fan-out + provider quota).
# Set to a positive integer (ex: 20). 0/empty disables.
# AUTOMATION_MAX_RECORDINGS_PER_FICHE="0"

# Automation email notifications (optional SMTP)
# SMTP_HOST=""
# SMTP_PORT="587"
# SMTP_SECURE="0" # set to "1" (or use port 465) for SMTPS
# SMTP_USER=""
# SMTP_PASS=""
# SMTP_FROM="" # if empty, falls back to SMTP_USER
# SMTP_TIMEOUT_MS="10000"

# Server
PORT="3002"
NODE_ENV="development"

# Docker Compose / ports (optional; used by compose files for host bindings)
# SERVER_PORT="3002"
# INNGEST_PORT="8288"
# INNGEST_CONNECT_PORT="8289"
# REDIS_PORT="6379"

# Docker scaling hint (optional; used by concurrency auto-scaling)
# Keep this in sync with: `docker compose ... --scale server=N`
# SERVER_REPLICAS="1"

# Fiche sales-list fetch behavior
# Include recordings metadata in sales-list fetches (recommended: "1").
# If "0", some flows may need to fetch full fiche details earlier to see recordings.
# FICHE_SALES_INCLUDE_RECORDINGS="1"
