services:
  redis:
    image: redis:7-alpine
    restart: always
    # No host port published by default (internal-only). If you need local access,
    # temporarily add: ports: ["127.0.0.1:${REDIS_PORT:-6379}:6379"]
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Internal load balancer for the `server` replicas.
  # Publish this port and point your host nginx / domain at it.
  lb:
    image: nginx:1.27-alpine
    restart: always
    ports:
      # Bind to localhost; put your public Nginx in front for :80/:443.
      - "0.0.0.0:${SERVER_PORT:-3002}:80"
    volumes:
      - ./deploy/nginx-lb.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "nginx", "-t"]
      interval: 10s
      timeout: 3s
      retries: 30
      start_period: 5s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Main API Server (scale this to 3 replicas)
  # Usage: `docker compose -f docker-compose.prod.scale.yml up -d --build --scale server=3`
  server:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: always
    env_file:
      - ${ENV_FILE:-.env}
    environment:
      - NODE_ENV=production
      - PORT=${PORT:-3002}
      - DATABASE_URL=${DATABASE_URL}
      - DIRECT_URL=${DIRECT_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - FICHE_API_BASE_URL=${FICHE_API_BASE_URL}
      - FICHE_API_URL=${FICHE_API_URL}
      - FICHE_API_AUTH_TOKEN=${FICHE_API_AUTH_TOKEN}
      - FICHE_SALES_INCLUDE_RECORDINGS=${FICHE_SALES_INCLUDE_RECORDINGS:-1}
      - VECTOR_STORE_ID=${VECTOR_STORE_ID}
      - VECTOR_STORE_MAX_RESULTS=${VECTOR_STORE_MAX_RESULTS:-5}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      - OPENAI_MODEL_AUDIT=${OPENAI_MODEL_AUDIT:-gpt-5.2}
      - OPENAI_MODEL_CHAT=${OPENAI_MODEL_CHAT:-gpt-5.2}
      - OPENAI_TEMPERATURE_CHAT=${OPENAI_TEMPERATURE_CHAT:-0}
      - AUDIT_EVIDENCE_GATING=${AUDIT_EVIDENCE_GATING:-1}
      - PRODUCT_VECTORSTORE_FALLBACK=${PRODUCT_VECTORSTORE_FALLBACK:-0}
      - AUDIT_STEP_TIMELINE_EXCERPT=${AUDIT_STEP_TIMELINE_EXCERPT:-1}
      - AUDIT_STEP_TIMELINE_MAX_CHUNKS=${AUDIT_STEP_TIMELINE_MAX_CHUNKS:-40}
      - AUTOMATION_SCHEDULER_CRON=${AUTOMATION_SCHEDULER_CRON:-*/1 * * * *}
      - AUTOMATION_SCHEDULER_WINDOW_MINUTES=${AUTOMATION_SCHEDULER_WINDOW_MINUTES:-20}
      - AUTOMATION_MAX_RECORDINGS_PER_FICHE=${AUTOMATION_MAX_RECORDINGS_PER_FICHE:-0}
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_SECURE=${SMTP_SECURE:-0}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASS=${SMTP_PASS}
      - SMTP_FROM=${SMTP_FROM}
      - SMTP_TIMEOUT_MS=${SMTP_TIMEOUT_MS:-10000}
      - SERVER_REPLICAS=${SERVER_REPLICAS:-6}
      # JWT / Auth
      - JWT_ACCESS_SECRET=${JWT_ACCESS_SECRET}
      - JWT_ISSUER=${JWT_ISSUER:-ai-audit}
      - JWT_AUDIENCE=${JWT_AUDIENCE:-ai-audit}
      - AUTH_ACCESS_TTL_SECONDS=${AUTH_ACCESS_TTL_SECONDS:-900}
      - AUTH_REFRESH_TTL_SECONDS=${AUTH_REFRESH_TTL_SECONDS:-2592000}
      - AUTH_REFRESH_COOKIE_NAME=${AUTH_REFRESH_COOKIE_NAME:-refresh_token}
      - AUTH_COOKIE_SECURE=${AUTH_COOKIE_SECURE}
      - AUTH_COOKIE_SAMESITE=${AUTH_COOKIE_SAMESITE:-lax}
      - AUTH_SEED_ADMIN_EMAIL=${AUTH_SEED_ADMIN_EMAIL}
      - AUTH_SEED_ADMIN_PASSWORD=${AUTH_SEED_ADMIN_PASSWORD}
      - API_AUTH_TOKEN=${API_AUTH_TOKEN}
      # Inngest / Schedule
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_BASE_URL=http://inngest:8288
      - INNGEST_DEV=${INNGEST_DEV:-0}
      - INNGEST_PORT=${INNGEST_PORT:-8288}
      - INNGEST_CONNECT_PORT=${INNGEST_CONNECT_PORT:-8289}
      - INNGEST_PARALLELISM_PER_SERVER=${INNGEST_PARALLELISM_PER_SERVER:-10}
      - INNGEST_SERVER_REPLICAS=${SERVER_REPLICAS:-6}
      - INNGEST_POLL_INTERVAL=${INNGEST_POLL_INTERVAL:-60}
      # Webhooks
      - FRONTEND_WEBHOOK_URL=${FRONTEND_WEBHOOK_URL}
      - WEBHOOK_SECRET=${WEBHOOK_SECRET}
      - WEBHOOK_TIMEOUT=${WEBHOOK_TIMEOUT:-10000}
      - WEBHOOK_MAX_ATTEMPTS=${WEBHOOK_MAX_ATTEMPTS:-3}
      - WEBHOOK_ALLOWED_ORIGINS=${WEBHOOK_ALLOWED_ORIGINS}
      # Pusher
      - PUSHER_APP_ID=${PUSHER_APP_ID}
      - PUSHER_KEY=${PUSHER_KEY}
      - PUSHER_SECRET=${PUSHER_SECRET}
      - PUSHER_CLUSTER=${PUSHER_CLUSTER}
      - PUSHER_USE_PRIVATE_CHANNELS=${PUSHER_USE_PRIVATE_CHANNELS:-1}
      - PUSHER_MAX_PAYLOAD_BYTES=${PUSHER_MAX_PAYLOAD_BYTES:-9000}
      - PUSHER_DRY_RUN=${PUSHER_DRY_RUN:-0}
      # Logging
      - WORKFLOW_LOG_DB_ENABLED=${WORKFLOW_LOG_DB_ENABLED:-1}
      - WORKFLOW_DEBUG_LOG_TO_FILE=${WORKFLOW_DEBUG_LOG_TO_FILE:-1}
      - AUDIT_DEBUG_LOG_TO_FILE=${AUDIT_DEBUG_LOG_TO_FILE:-1}
      - TRANSCRIPTION_DEBUG_LOG_TO_FILE=${TRANSCRIPTION_DEBUG_LOG_TO_FILE:-1}
      - FICHE_DEBUG_LOG_TO_FILE=${FICHE_DEBUG_LOG_TO_FILE:-1}
      - AUTOMATION_DEBUG_LOG_TO_FILE=${AUTOMATION_DEBUG_LOG_TO_FILE:-1}
      # Transcription throughput tuning
      # Empty default = let the code auto-calculate from replicas * parallelism
      - TRANSCRIPTION_ELEVENLABS_RATE_LIMIT_PER_MINUTE=${TRANSCRIPTION_ELEVENLABS_RATE_LIMIT_PER_MINUTE:-60}
    volumes:
      - audit-data:/app/data
    networks:
      - ai-audit-network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:${PORT:-3002}/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Inngest Self-Hosted Server (single instance)
  # IMPORTANT: point sdk-url at the load balancer so invocations distribute across replicas.
  inngest:
    image: inngest/inngest:latest
    restart: always
    ports:
      - "0.0.0.0:${INNGEST_PORT:-8288}:8288"
      - "0.0.0.0:${INNGEST_CONNECT_PORT:-8289}:8289"
    environment:
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_LOG_LEVEL=info
      - INNGEST_POLL_INTERVAL=${INNGEST_POLL_INTERVAL:-60}
      - INNGEST_SDK_URL=${INNGEST_SDK_URL:-http://lb/api/inngest}
    command: inngest start --sdk-url ${INNGEST_SDK_URL:-http://lb/api/inngest} --poll-interval ${INNGEST_POLL_INTERVAL:-60}
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8288/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      lb:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  ai-audit-network:
    driver: bridge

volumes:
  audit-data:
    driver: local
  redis-data:
    driver: local
