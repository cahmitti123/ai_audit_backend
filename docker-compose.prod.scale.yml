services:
  redis:
    image: redis:7-alpine
    restart: always
    # No host port published by default (internal-only). If you need local access,
    # temporarily add: ports: ["127.0.0.1:${REDIS_PORT:-6379}:6379"]
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Internal load balancer for the `server` replicas.
  # Publish this port and point your host nginx / domain at it.
  lb:
    image: nginx:1.27-alpine
    restart: always
    ports:
      # Bind to localhost; put your public Nginx in front for :80/:443.
      - "0.0.0.0:${SERVER_PORT:-3002}:80"
    volumes:
      - ./deploy/nginx-lb.conf:/etc/nginx/conf.d/default.conf:ro
    networks:
      - ai-audit-network
    depends_on:
      - server
    healthcheck:
      test:
        [
          "CMD-SHELL",
          "wget -q -O - http://localhost/health >/dev/null 2>&1 || exit 1",
        ]
      interval: 10s
      timeout: 5s
      retries: 30
      # Must be longer than server start_period (60s) + time for at least
      # one of N replicas to pass its own health check. With 20 replicas
      # competing for resources at startup, 90s is a safe minimum.
      start_period: 90s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Main API Server (scale this to 3 replicas)
  # Usage: `docker compose -f docker-compose.prod.scale.yml up -d --build --scale server=3`
  server:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    restart: always
    # Inject all variables from the chosen env file into the container.
    # (Compose still uses `--env-file` for ${VAR} interpolation in this YAML.)
    env_file:
      - ${ENV_FILE:-.env}
    environment:
      - NODE_ENV=production
      - PORT=3002
      - DATABASE_URL=${DATABASE_URL}
      - DIRECT_URL=${DIRECT_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - FICHE_API_BASE_URL=${FICHE_API_BASE_URL}
      - FICHE_API_AUTH_TOKEN=${FICHE_API_AUTH_TOKEN}
      - FICHE_SALES_INCLUDE_RECORDINGS=${FICHE_SALES_INCLUDE_RECORDINGS:-1}
      # User authentication (JWT + refresh tokens)
      - JWT_ACCESS_SECRET=${JWT_ACCESS_SECRET}
      - JWT_ISSUER=${JWT_ISSUER:-ai-audit}
      - JWT_AUDIENCE=${JWT_AUDIENCE:-ai-audit}
      - AUTH_ACCESS_TTL_SECONDS=${AUTH_ACCESS_TTL_SECONDS:-900}
      - AUTH_REFRESH_TTL_SECONDS=${AUTH_REFRESH_TTL_SECONDS:-2592000}
      - AUTH_REFRESH_COOKIE_NAME=${AUTH_REFRESH_COOKIE_NAME:-refresh_token}
      - AUTH_COOKIE_SECURE=${AUTH_COOKIE_SECURE}
      - AUTH_COOKIE_SAMESITE=${AUTH_COOKIE_SAMESITE:-lax}
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_BASE_URL=http://inngest:8288
      - INNGEST_DEV=0
      - WEBHOOK_ALLOWED_ORIGINS=${WEBHOOK_ALLOWED_ORIGINS}
      # Pusher Channels (server-side publishing)
      - PUSHER_APP_ID=${PUSHER_APP_ID}
      - PUSHER_KEY=${PUSHER_KEY}
      - PUSHER_SECRET=${PUSHER_SECRET}
      - PUSHER_CLUSTER=${PUSHER_CLUSTER}
      - PUSHER_USE_PRIVATE_CHANNELS=${PUSHER_USE_PRIVATE_CHANNELS:-1}
      - PUSHER_MAX_PAYLOAD_BYTES=${PUSHER_MAX_PAYLOAD_BYTES:-9000}
      - VECTOR_STORE_ID=${VECTOR_STORE_ID}
      - VECTOR_STORE_MAX_RESULTS=${VECTOR_STORE_MAX_RESULTS:-5}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      - OPENAI_MODEL_AUDIT=${OPENAI_MODEL_AUDIT:-gpt-5.2}
      - OPENAI_MODEL_CHAT=${OPENAI_MODEL_CHAT:-gpt-5.2}
      - OPENAI_TEMPERATURE_CHAT=${OPENAI_TEMPERATURE_CHAT:-0}
      - AUDIT_EVIDENCE_GATING=${AUDIT_EVIDENCE_GATING:-1}
      - PRODUCT_VECTORSTORE_FALLBACK=${PRODUCT_VECTORSTORE_FALLBACK:-0}
      - AUDIT_STEP_TIMELINE_EXCERPT=${AUDIT_STEP_TIMELINE_EXCERPT:-1}
      - AUDIT_STEP_TIMELINE_MAX_CHUNKS=${AUDIT_STEP_TIMELINE_MAX_CHUNKS:-40}
      - AUTOMATION_SCHEDULER_CRON=${AUTOMATION_SCHEDULER_CRON:-*/1 * * * *}
      - AUTOMATION_SCHEDULER_WINDOW_MINUTES=${AUTOMATION_SCHEDULER_WINDOW_MINUTES:-20}
      - AUTOMATION_MAX_RECORDINGS_PER_FICHE=${AUTOMATION_MAX_RECORDINGS_PER_FICHE:-0}
      # Optional: seed an initial admin user (idempotent). Remove after first deploy if desired.
      - AUTH_SEED_ADMIN_EMAIL=${AUTH_SEED_ADMIN_EMAIL}
      - AUTH_SEED_ADMIN_PASSWORD=${AUTH_SEED_ADMIN_PASSWORD}
      # Inngest scaling:
      # - INNGEST_PARALLELISM_PER_SERVER: how many tasks each server replica can run in parallel (default 10)
      # - INNGEST_SERVER_REPLICAS: how many `server` containers you scaled to (ex: --scale server=6)
      - INNGEST_PARALLELISM_PER_SERVER=${INNGEST_PARALLELISM_PER_SERVER:-10}
      - INNGEST_SERVER_REPLICAS=${SERVER_REPLICAS:-6}
    volumes:
      - audit-data:/app/data
    networks:
      - ai-audit-network
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:3002/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Inngest Self-Hosted Server (single instance)
  # IMPORTANT: point sdk-url at the load balancer so invocations distribute across replicas.
  inngest:
    image: inngest/inngest:latest
    restart: always
    ports:
      # Bind to localhost (access UI via SSH tunnel in prod).
      - "0.0.0.0:${INNGEST_PORT:-8288}:8288"
      - "0.0.0.0:${INNGEST_CONNECT_PORT:-8289}:8289"
    environment:
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_LOG_LEVEL=info
      - INNGEST_POLL_INTERVAL=${INNGEST_POLL_INTERVAL:-60}
    # Default to the load balancer so invocations distribute across replicas.
    # If you ever need a "bypass LB" fallback, set INNGEST_SDK_URL=http://server:3002/api/inngest.
    command: inngest start --sdk-url ${INNGEST_SDK_URL:-http://lb/api/inngest} --poll-interval ${INNGEST_POLL_INTERVAL:-60}
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8288/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      lb:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  ai-audit-network:
    driver: bridge

volumes:
  audit-data:
    driver: local
  redis-data:
    driver: local


