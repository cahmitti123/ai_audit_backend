version: "3.8"

# Production Docker Compose Configuration
# Usage: docker-compose -f docker-compose.prod.yml up -d

services:
  redis:
    image: redis:7-alpine
    container_name: ai-audit-redis-prod
    restart: always
    ports:
      # Bind to localhost; do not expose Redis publicly.
      - "127.0.0.1:${REDIS_PORT:-6379}:6379"
    command: ["redis-server", "--appendonly", "yes"]
    volumes:
      - redis-data:/data
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 10
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Main API Server
  server:
    build:
      context: .
      dockerfile: Dockerfile
      target: production
    container_name: ai-audit-server-prod
    restart: always
    ports:
      # Bind to localhost; put host Nginx/HTTPS in front of this port.
      - "0.0.0.0:${SERVER_PORT:-3002}:3002"
    environment:
      - NODE_ENV=production
      - PORT=3002
      - DATABASE_URL=${DATABASE_URL}
      - DIRECT_URL=${DIRECT_URL}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - ELEVENLABS_API_KEY=${ELEVENLABS_API_KEY}
      - FICHE_API_BASE_URL=${FICHE_API_BASE_URL}
      - FICHE_API_AUTH_TOKEN=${FICHE_API_AUTH_TOKEN}
      # Optional AI/model tuning
      - OPENAI_MODEL_AUDIT=${OPENAI_MODEL_AUDIT:-gpt-5.2}
      - OPENAI_MODEL_CHAT=${OPENAI_MODEL_CHAT:-gpt-5.2}
      - OPENAI_TEMPERATURE_CHAT=${OPENAI_TEMPERATURE_CHAT:-0}
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_BASE_URL=http://inngest:8288
      - INNGEST_DEV=0
      # Scaling/concurrency (single instance defaults)
      - INNGEST_PARALLELISM_PER_SERVER=${INNGEST_PARALLELISM_PER_SERVER:-10}
      - INNGEST_SERVER_REPLICAS=${SERVER_REPLICAS:-1}
      - WEBHOOK_ALLOWED_ORIGINS=${WEBHOOK_ALLOWED_ORIGINS}
      # Pusher Channels (server-side publishing)
      - PUSHER_APP_ID=${PUSHER_APP_ID}
      - PUSHER_KEY=${PUSHER_KEY}
      - PUSHER_SECRET=${PUSHER_SECRET}
      - PUSHER_CLUSTER=${PUSHER_CLUSTER}
      - PUSHER_USE_PRIVATE_CHANNELS=${PUSHER_USE_PRIVATE_CHANNELS:-1}
      - PUSHER_MAX_PAYLOAD_BYTES=${PUSHER_MAX_PAYLOAD_BYTES:-9000}
      - VECTOR_STORE_ID=${VECTOR_STORE_ID}
      - VECTOR_STORE_MAX_RESULTS=${VECTOR_STORE_MAX_RESULTS:-5}
      # Audit behavior
      - AUDIT_EVIDENCE_GATING=${AUDIT_EVIDENCE_GATING:-1}
      - PRODUCT_VECTORSTORE_FALLBACK=${PRODUCT_VECTORSTORE_FALLBACK:-0}
      - AUDIT_STEP_TIMELINE_EXCERPT=${AUDIT_STEP_TIMELINE_EXCERPT:-1}
      - AUDIT_STEP_TIMELINE_MAX_CHUNKS=${AUDIT_STEP_TIMELINE_MAX_CHUNKS:-40}
      - REDIS_URL=${REDIS_URL:-redis://redis:6379}
      # Automation scheduler
      - AUTOMATION_SCHEDULER_CRON=${AUTOMATION_SCHEDULER_CRON:-0 * * * *}
      - AUTOMATION_SCHEDULER_WINDOW_MINUTES=${AUTOMATION_SCHEDULER_WINDOW_MINUTES:-20}
      - AUTOMATION_MAX_RECORDINGS_PER_FICHE=${AUTOMATION_MAX_RECORDINGS_PER_FICHE:-0}
      # Distributed worker concurrency (single replica defaults)
      - AUDIT_STEP_WORKER_CONCURRENCY=${AUDIT_STEP_WORKER_CONCURRENCY:-5}
      - AUDIT_STEP_PER_AUDIT_CONCURRENCY=${AUDIT_STEP_PER_AUDIT_CONCURRENCY:-5}
      - TRANSCRIPTION_RECORDING_WORKER_CONCURRENCY=${TRANSCRIPTION_RECORDING_WORKER_CONCURRENCY:-5}
      - TRANSCRIPTION_RECORDING_PER_FICHE_CONCURRENCY=${TRANSCRIPTION_RECORDING_PER_FICHE_CONCURRENCY:-5}
      - FICHE_SALES_INCLUDE_RECORDINGS=${FICHE_SALES_INCLUDE_RECORDINGS:-1}
    volumes:
      - audit-data:/app/data
    networks:
      - ai-audit-network
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "require('http').get('http://localhost:3002/health', (r) => {process.exit(r.statusCode === 200 ? 0 : 1)})",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: 2G
        reservations:
          cpus: "1"
          memory: 512M
    depends_on:
      redis:
        condition: service_healthy

  # Inngest Self-Hosted Server (Production)
  inngest:
    image: inngest/inngest:latest
    container_name: ai-audit-inngest-prod
    restart: always
    ports:
      # Bind to localhost; access UI via SSH tunnel.
      - "0.0.0.0:${INNGEST_PORT:-8288}:8288"
      - "0.0.0.0:${INNGEST_CONNECT_PORT:-8289}:8289"
    environment:
      - INNGEST_EVENT_KEY=${INNGEST_EVENT_KEY}
      - INNGEST_SIGNING_KEY=${INNGEST_SIGNING_KEY}
      - INNGEST_LOG_LEVEL=info
      - INNGEST_POLL_INTERVAL=${INNGEST_POLL_INTERVAL:-60}
    command: inngest start --sdk-url http://server:3002/api/inngest --poll-interval ${INNGEST_POLL_INTERVAL:-60}
    networks:
      - ai-audit-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8288/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    depends_on:
      server:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1G
        reservations:
          cpus: "0.5"
          memory: 256M

networks:
  ai-audit-network:
    driver: bridge

volumes:
  audit-data:
    driver: local
  redis-data:
    driver: local
